[
  {
    "iteration": 1,
    "total_timesteps": 800,
    "total_episodes": 50,
    "mean_episode_reward": 10.44,
    "mean_episode_length": 16.0,
    "policy_lr": 0.009000000000000001,
    "value_lr": 0.009000000000000001,
    "policy_loss": -0.04939293535426259,
    "value_loss": 87.5768210887909,
    "mean_advantage": 3.33786012163273e-08,
    "mean_return": 5.642999172210693
  },
  {
    "iteration": 2,
    "total_timesteps": 1600,
    "total_episodes": 100,
    "mean_episode_reward": 10.98,
    "mean_episode_length": 16.0,
    "policy_lr": 0.008,
    "value_lr": 0.008,
    "policy_loss": -0.04850340250413865,
    "value_loss": 74.16883897781372,
    "mean_advantage": 3.814697180359872e-08,
    "mean_return": 6.226758003234863
  },
  {
    "iteration": 3,
    "total_timesteps": 2400,
    "total_episodes": 150,
    "mean_episode_reward": 12.6,
    "mean_episode_length": 16.0,
    "policy_lr": 0.007,
    "value_lr": 0.007,
    "policy_loss": -0.04890978313051164,
    "value_loss": 58.548978328704834,
    "mean_advantage": -4.7683716530855236e-08,
    "mean_return": 7.394274711608887
  },
  {
    "iteration": 4,
    "total_timesteps": 3200,
    "total_episodes": 200,
    "mean_episode_reward": 14.58,
    "mean_episode_length": 16.0,
    "policy_lr": 0.006000000000000001,
    "value_lr": 0.006000000000000001,
    "policy_loss": -0.04649303725454956,
    "value_loss": 38.990551352500916,
    "mean_advantage": -9.53674295089968e-09,
    "mean_return": 8.367206573486328
  },
  {
    "iteration": 5,
    "total_timesteps": 4000,
    "total_episodes": 250,
    "mean_episode_reward": 15.66,
    "mean_episode_length": 16.0,
    "policy_lr": 0.005000000000000001,
    "value_lr": 0.005000000000000001,
    "policy_loss": -0.05954379483591765,
    "value_loss": 32.85786509513855,
    "mean_advantage": -2.3841858265427618e-08,
    "mean_return": 8.561793327331543
  },
  {
    "iteration": 6,
    "total_timesteps": 4800,
    "total_episodes": 300,
    "mean_episode_reward": 16.2,
    "mean_episode_length": 16.0,
    "policy_lr": 0.004000000000000001,
    "value_lr": 0.004000000000000001,
    "policy_loss": -0.03580175980459899,
    "value_loss": 29.998624086380005,
    "mean_advantage": 9.53674295089968e-09,
    "mean_return": 8.95096492767334
  },
  {
    "iteration": 7,
    "total_timesteps": 5600,
    "total_episodes": 350,
    "mean_episode_reward": 16.92,
    "mean_episode_length": 16.0,
    "policy_lr": 0.003000000000000001,
    "value_lr": 0.003000000000000001,
    "policy_loss": -0.03685830580070615,
    "value_loss": 26.885669469833374,
    "mean_advantage": 0.0,
    "mean_return": 9.340137481689453
  },
  {
    "iteration": 8,
    "total_timesteps": 6400,
    "total_episodes": 400,
    "mean_episode_reward": 17.64,
    "mean_episode_length": 16.0,
    "policy_lr": 0.002000000000000001,
    "value_lr": 0.002000000000000001,
    "policy_loss": -0.033881146810017526,
    "value_loss": 20.463687419891357,
    "mean_advantage": 1.4305114426349519e-08,
    "mean_return": 9.729310035705566
  },
  {
    "iteration": 9,
    "total_timesteps": 7200,
    "total_episodes": 450,
    "mean_episode_reward": 17.64,
    "mean_episode_length": 16.0,
    "policy_lr": 0.0010000000000000005,
    "value_lr": 0.0010000000000000005,
    "policy_loss": -0.03697046369779855,
    "value_loss": 24.221271097660065,
    "mean_advantage": 1.907348590179936e-08,
    "mean_return": 9.340137481689453
  },
  {
    "iteration": 10,
    "total_timesteps": 8000,
    "total_episodes": 500,
    "mean_episode_reward": 17.64,
    "mean_episode_length": 16.0,
    "policy_lr": 0.0,
    "value_lr": 0.0,
    "policy_loss": -0.03500533592887223,
    "value_loss": 21.04570186138153,
    "mean_advantage": -2.3841858265427618e-08,
    "mean_return": 9.729310035705566
  }
]